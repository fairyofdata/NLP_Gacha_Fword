{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3088,"status":"ok","timestamp":1655644163578,"user":{"displayName":"알리오올리오","userId":"09105723902349046909"},"user_tz":-540},"id":"QFgSw-qJZSpW","outputId":"790df025-4a18-415e-b27f-1083f96f929c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n"]}],"source":["!pip install konlpy #한글 형태소 분석 라이브러리"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3566,"status":"ok","timestamp":1655644167142,"user":{"displayName":"알리오올리오","userId":"09105723902349046909"},"user_tz":-540},"id":"NKY8B_4w9u-S","outputId":"eb9f15c2-8cfa-453e-9fc0-8b0dc561c85d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pymysql in /usr/local/lib/python3.7/dist-packages (1.0.2)\n"]}],"source":["!pip install pymysql"]},{"cell_type":"code","source":["!pip install gensim --upgrade"],"metadata":{"id":"rJ4YxBKKEKcn","executionInfo":{"status":"ok","timestamp":1655644170741,"user_tz":-540,"elapsed":3604,"user":{"displayName":"알리오올리오","userId":"09105723902349046909"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"48298681-30aa-46c9-a248-380590278e1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.2.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0cc0U84_sjAk","executionInfo":{"status":"ok","timestamp":1655644172764,"user_tz":-540,"elapsed":2026,"user":{"displayName":"알리오올리오","userId":"09105723902349046909"}},"outputId":"384afdb0-fcfd-4798-a523-be0ef9166b07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJx_aJBuszHm","executionInfo":{"status":"ok","timestamp":1655644172764,"user_tz":-540,"elapsed":4,"user":{"displayName":"알리오올리오","userId":"09105723902349046909"}},"outputId":"feddbff3-2373-41d8-a0e3-e2e312bf633a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1l_AUpAUvG2xbujGqvp7y2aivnC4LEEtP/[DS13&14] 문제해결 빅데이터 PJT_2조/튜닝 완료 모델/소프트 보팅\n"]}],"source":["cd /content/drive/MyDrive/[DS13&14] 문제해결 빅데이터 PJT_2조/튜닝 완료 모델/소프트 보팅"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTM26wS1tTGn"},"outputs":[],"source":["import pickle\n","from tensorflow.keras.models import load_model\n","from konlpy.tag import Okt\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import pandas as pd\n","from gensim.models import FastText\n","okt = Okt()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAhS67qcZH0c"},"outputs":[],"source":["FIRST_HANGUL = 0xAC00 #'가'\n","LAST_HANGUL = 0xD7A3 #'힣'\n","NO_JONGSUNG = 'ᴕ'\n","\n","CHOSUNGS = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n","JOONGSUNGS = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n","JONGSUNGS = [NO_JONGSUNG,  'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n","\n","N_CHOSUNGS = 19\n","N_JOONGSUNGS = 21\n","N_JONGSUNGS = 28\n","\n","def to_jamo(s):        \n","    result = []\n","    for c in s:\n","        if ord(c) < FIRST_HANGUL or ord(c) > LAST_HANGUL: # if a character is a hangul\n","            result.append(c)\n","        else:            \n","            code = ord(c) - FIRST_HANGUL\n","            jongsung_index = code % N_JONGSUNGS\n","            code //= N_JONGSUNGS\n","            joongsung_index = code % N_JOONGSUNGS\n","            code //= N_JOONGSUNGS\n","            chosung_index = code\n","\n","            result.append(CHOSUNGS[chosung_index])\n","            result.append(JOONGSUNGS[joongsung_index])\n","            result.append(JONGSUNGS[jongsung_index])\n","    \n","    return ''.join(result) \n","\n","def bunhae(s):\n","    return [to_jamo(i) for i in s]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-aL6Nlu4dMMK"},"outputs":[],"source":["from tqdm import tqdm\n","\n","def process_jamo(tokenized_corpus_fname, output_fname):\n","    toatal_lines = sum(1 for line in open(tokenized_corpus_fname, 'r', encoding='utf-8'))\n","\n","    with open(tokenized_corpus_fname, 'r', encoding='utf-8') as f1, \\\n","            open(output_fname, 'w', encoding='utf-8') as f2:\n","\n","        for _, line in tqdm(enumerate(f1), total=toatal_lines):\n","            sentence = line.replace('\\n', '').strip()\n","            processed_sentence = jamo_sentence(sentence)\n","            f2.writelines(processed_sentence + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSsrKNuTji56","executionInfo":{"status":"ok","timestamp":1655644181309,"user_tz":-540,"elapsed":4166,"user":{"displayName":"알리오올리오","userId":"09105723902349046909"}},"outputId":"bed6ba9c-afdc-4f4a-9330-3f230c7695bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: soynlp in /usr/local/lib/python3.7/dist-packages (0.0.493)\n","Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.0.2)\n","Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.21.6)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n"]}],"source":["!pip install soynlp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rVOGktenjAxE"},"outputs":[],"source":["import re\n","from soynlp.hangle import compose, decompose, character_is_korean\n","doublespace_pattern = re.compile('\\s+')\n","\n","\n","def jamo_sentence(sent):\n","    def transform(char):\n","        if char == ' ':\n","            return char\n","        cjj = decompose(char)\n","        if len(cjj) == 1:\n","            return cjj\n","        cjj_ = ''.join(c if c != ' ' else '-' for c in cjj)\n","        return cjj_\n","\n","    sent_ = []\n","    for char in sent:\n","        if character_is_korean(char):\n","            sent_.append(transform(char))\n","        else:\n","            sent_.append(char)\n","    sent_ = doublespace_pattern.sub(' ', ''.join(sent_))\n","    return sent_\n","\n","def jamo_to_word(jamo):\n","    jamo_list, idx = [], 0\n","    while idx < len(jamo):\n","        if not character_is_korean(jamo[idx]):\n","            jamo_list.append(jamo[idx])\n","            idx += 1\n","        else:\n","            jamo_list.append(jamo[idx:idx + 3])\n","            idx += 3\n","    word = \"\"\n","\n","    try:\n","      for jamo_char in jamo_list:\n","          if len(jamo_char) == 1:\n","\n","              word += jamo_char\n","\n","          elif jamo_char[2] == \"-\":\n","              \n","              try:\n","                word += compose(jamo_char[0], jamo_char[1], \" \")\n","              except:\n","                word += jamo_char\n","                continue\n","          else:\n","              try:\n","                word += compose(jamo_char[0], jamo_char[1], jamo_char[2])\n","              except:\n","                word += jamo_char\n","                continue\n","    except:\n","      pass\n","      \n","    return word"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZRVxSZSXiGJ"},"outputs":[],"source":["loaded_model1 = load_model('wordlstm/wordlstm.h5') # LSTM 형태소 모델 로드\n","loaded_model2 = load_model('jamolstm/jamolstm.h5') # LSTM 자모 모델 로드\n","loaded_model3 = load_model('jamocnn/jamocnn.h5') # CNN 자모 모델 로드\n","loaded_model4 = load_model('jamofastlstm/jamofastlstm.h5') # fasttext + lstm 자모 모델 로드\n","model_morphs = FastText.load(\"jamofastlstm/jamofastlstm.model\") # fasttext + lstm 자모 모델 로드\n","\n","\n","with open('wordlstm/wordlstm.pkl', 'rb') as f: # LSTM 형태소 단어사전 로드\n","\ttokenizer1 = pickle.load(f)\n"," \n","with open('jamolstm/jamolstm.pkl', 'rb') as f: # LSTM 자모 단어사전 로드\n","\ttokenizer2 = pickle.load(f)\n"," \n","with open('jamocnn/jamocnn.pkl', 'rb') as f: # CNN 자모 단어사전 로드\n","\ttokenizer3 = pickle.load(f)\n"," \n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bV11XM_YAnz"},"outputs":[],"source":["def predict_test(new_sentence):\n","\n","\n","  new_sentence1 = okt.morphs(new_sentence, stem=True) # 토큰화\n","  encoded1 = tokenizer1.texts_to_sequences([new_sentence1]) # 정수 인코딩\n","  pad_new1 = pad_sequences(encoded1, maxlen = 10) # 패딩\n","  score1 = float(loaded_model1.predict(pad_new1)) # 예측\n","\n","  new_sentence2 = list(\"\".join(bunhae(new_sentence)))\n","  encoded2 = tokenizer2.texts_to_sequences([new_sentence2]) # 정수 인코딩\n","  pad_new2 = pad_sequences(encoded2, maxlen = 100) # 패딩\n","  score2 = float(loaded_model2.predict(pad_new2)) # 예측\n","\n","  new_sentence3 = list(\"\".join(bunhae(new_sentence)))\n","  encoded3 = tokenizer3.texts_to_sequences([new_sentence3]) # 정수 인코딩\n","  pad_new3 = pad_sequences(encoded3, maxlen = 100) # 패딩\n","  score3 = float(loaded_model3.predict(pad_new3)) # 예측\n","\n","  new_sentence4 = [new_sentence]\n","  pd.DataFrame(new_sentence4).to_csv('jamofastlstm/sentence.txt',index = False, header = False)\n","  sentence_txt = 'jamofastlstm/sentence.txt'\n","  new_sentence_txt = 'jamofastlstm/newsentence.txt'\n","  process_jamo(sentence_txt, new_sentence_txt)\n","  new_sentence_final = [sent.strip().split(\" \") for sent in tqdm(open(new_sentence_txt, 'r', encoding='utf-8').readlines())]\n","  new_sentencelist = []\n","  for a in new_sentence_final:\n","    new_sentencelist2 = []\n","    for word in a:\n","      ft_modeled = model_morphs.wv.get_vector(word)\n","      new_sentencelist2.append(ft_modeled)\n","    new_sentencelist.append(new_sentencelist2)\n","  score4 = float(loaded_model4.predict(pad_sequences(new_sentencelist, maxlen = 15, padding='post', truncating = 'post', dtype = float )))\n","\n","  score_average=(score1+score2+score3+score4)/4\n","\n","  if(score_average > 0.5):\n","    print(\"{:.2f}% 확률로 욕설입니다.\\n\".format(score_average * 100))\n","  else:\n","    print(\"{:.2f}% 확률로 욕설이 아닙니다.\\n\".format((1 - score_average) * 100))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebnAwgsqwKFr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655644210767,"user_tz":-540,"elapsed":10266,"user":{"displayName":"알리오올리오","userId":"09105723902349046909"}},"outputId":"6eeb67a2-6c47-4979-ffba-0be35156a4cf"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 429.35it/s]\n","100%|██████████| 1/1 [00:00<00:00, 8594.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["94.17% 확률로 욕설입니다.\n","\n"]}],"source":["predict_test('ㅈ같은련')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"소프트보팅.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}